{
    "version": "https://jsonfeed.org/version/1",
    "title": "zjxdiu~blog site • All posts by \"信号处理\" tag",
    "description": "",
    "home_page_url": "https://zjxdiu.github.io/zwork.io",
    "items": [
        {
            "id": "https://zjxdiu.github.io/zwork.io/blog/ML_emusic_classify/",
            "url": "https://zjxdiu.github.io/zwork.io/blog/ML_emusic_classify/",
            "title": "一种基于神经网络的电子音乐风格分类算法思路",
            "date_published": "2023-05-03T09:18:00.000Z",
            "content_html": "<h1 id=\"一种基于神经网络的电子音乐风格分类算法思路\"><a class=\"markdownIt-Anchor\" href=\"#一种基于神经网络的电子音乐风格分类算法思路\">#</a> 一种基于神经网络的电子音乐风格分类算法思路</h1>\n<h2 id=\"以zjxdiu常听的电子音乐风格为例\"><a class=\"markdownIt-Anchor\" href=\"#以zjxdiu常听的电子音乐风格为例\">#</a> —— 以 zjxdiu 常听的电子音乐风格为例</h2>\n<h1 id=\"目录\"><a class=\"markdownIt-Anchor\" href=\"#目录\">#</a> 目录</h1>\n<p>一、概述与引言<br>\n二、电子音乐风格<br>\n 2.1 主风格<br>\n 2.2 子风格<br>\n 2.3 混合风格与其他元素<br>\n三、现有解决方案<br>\n 3.1 传统人工分类<br>\n 3.2 特征提取技术<br>\n 3.3 现有机器学习算法<br>\n 3.3.1 实践项目：DeepAudioClassification<br>\n 四、SRM-DNN（频谱、节奏、情感分析 - 深度神经网络）思路<br>\n 4.1 电子音乐的频谱特征<br>\n 4.2 鼓与贝斯节奏分析<br>\n 4.3 BPM 与时间分析<br>\n 4.4 情感分析<br>\n 4.5 能量分析<br>\n 4.6 实现思路<br>\n 4.6.1 频谱提取<br>\n 4.6.2 DnB 分析<br>\n 4.6.3 BPM 与时间分析<br>\n 4.6.4 图像识别<br>\n 4.6.5 人声分离<br>\n 4.6.6 情感特征<br>\n五、总结</p>\n<hr>\n<h2 id=\"一-概述与引言\"><a class=\"markdownIt-Anchor\" href=\"#一-概述与引言\">#</a> 一、概述与引言</h2>\n<p>随着近年来计算机技术的快速发展，机器学习被应用于越来越多的领域。其中，最广泛的应用之一就是执行分类与识别任务，在音乐风格的识别与分类方面，同样有着应用的空间。为此，结合笔者生活中的实际痛点：难以区分部分电子音乐的风格，且现有方案难以准确识别细分风格，而撰写本文，希望以相对专业的视角提供一种新的解决方案。</p>\n<h2 id=\"二-电子音乐风格\"><a class=\"markdownIt-Anchor\" href=\"#二-电子音乐风格\">#</a> 二、电子音乐风格</h2>\n<p>电子音乐是音乐中的一个大类型，起源于 20 世纪 60 年代的欧美地区，是音乐文化中重要的一部分。其曲风特色是注重以节奏和旋律创建舞蹈氛围，主要使用各类合成器作为 “乐器”，并具有相对少量的歌词。在约 80 年的发展过程中，电子音乐衍生、拓展出非常多的细分风格，以下对笔者常听的风格进行简述。</p>\n<h3 id=\"21-主风格\"><a class=\"markdownIt-Anchor\" href=\"#21-主风格\">#</a> 2.1 主风格</h3>\n<p>zjxdiu 常听的电子音乐包括以下几类主要风格：</p>\n<ul>\n<li>House，浩室或浩室舞曲，注重旋律和音色的展现，编曲的格式化比较显著，节奏简单且 “软硬” 适中；</li>\n<li>Trance，迷幻舞曲，BPM 相对 House 更高一些，鼓点一般位于每个 1/2 beat 上，但较为柔和；snare 和 hat 也在 DnB 序列中以更高频率出现，每节旋律相似但不重复。整体听感与其名字类似，为 “迷幻”。</li>\n<li>Core，核，主要包括 Hardcore（硬核）和 Frenchcore（法核，也可一并归类为 Hardcore），表现为更为强烈的节奏和鼓点，BPM 也更高，且对人声的处理更极端；部分早期的 Core 十分的 “硬”，以至于很少人能够承受；而近年的新型 core 则相对柔软一些，并且对于旋律和人声的体现也更为注重。</li>\n<li>Hardstyle，硬派，其显著特征为 bass 和 drum 同时出现，且多使用经失真处理的 bassline，由于其独特的 DnB 听感，时常被开玩笑：“听到 duang duang duang 就是 hardstyle”。其软硬程序介于 Core 与 House 之间。</li>\n<li>Hands Up，无中文名，是一种处于 Core 与 Hardstyle 之间、更接近 Core 的风格，其特征为较为快速和低沉的鼓点，且旋律表现力强、与 DnB 的融合程度高，编曲方面则接近 House，在许多 Disco 舞厅音乐中较为常见。</li>\n<li>Chill Out，弛放音乐，它的特征最为显著，即一反常派的柔和与宁静。通常其编曲较为接近 Trance，但使用的音色极为柔软，鼓点和贝斯的响度也很低，BPM 通常也较低，听感上呈现 “飘渺舒缓的节奏，柔和的合成器音效，空灵的女声吟唱，悠远的环境音”。</li>\n</ul>\n<h3 id=\"22-子风格\"><a class=\"markdownIt-Anchor\" href=\"#22-子风格\">#</a> 2.2 子风格</h3>\n<p>常见子风格见如下虚表格：<br>\n<img src=\"../_resources/7019e2a17be54b2c468752025c2ca3c9.png\" alt=\"7019e2a17be54b2c468752025c2ca3c9.png\"><br>\n 需要注意的是，此处列出的仅为一部分，实际上还可区分为数倍于列表项目数的子风格。</p>\n<h3 id=\"23-混合风格与其他元素\"><a class=\"markdownIt-Anchor\" href=\"#23-混合风格与其他元素\">#</a> 2.3 混合风格与其他元素</h3>\n<p>对于现代电子音乐而言，一首音乐混合多种风格的做法是十分常见的；例如 Hands Up+Hardstyle、Melodic House+Hardstyle、Progressive House+Future House 等等。不过对于大多数音乐而言，其主要曲风只会有一种。<br>\n此外，部分曲风还会有一些其他元素；例如 Midtempo 指 BPM 在约 80~120 之间的，带人声和歌词的 Trance 可称为 Vocal Trance 等。总之，电子音乐的曲风是难以准确、完全判别的，因此可考虑采用标签（label）的方式进行风格判断。</p>\n<h2 id=\"三-现有解决方案\"><a class=\"markdownIt-Anchor\" href=\"#三-现有解决方案\">#</a> 三、现有解决方案</h2>\n<h3 id=\"31-传统人工分类\"><a class=\"markdownIt-Anchor\" href=\"#31-传统人工分类\">#</a> 3.1 传统人工分类</h3>\n<p>显然，音乐分类可由人工进行；无论是音乐人提供还是听众、鉴赏家提供，都属于人工分类方法。在任何涉及到机器学习与人类学习对比的地方都能得知，人工方法一般有准确率高、复杂任务处理能力强、误报率低、学习速度快且成本低等优点，但其识别速度相比于计算机而言则无法比拟。</p>\n<h3 id=\"32-特征提取技术\"><a class=\"markdownIt-Anchor\" href=\"#32-特征提取技术\">#</a> 3.2 特征提取技术</h3>\n<p>参考文献：<a href=\"https://www.hindawi.com/journals/wcmc/2021/9298654/\">基于音乐特征提取和深度神经网络的音乐风格分类算法</a><br>\n对于通常意义上的音乐而言，我们可以通过提取音乐特征进行分析与识别。这些特征包括节奏、旋律、乐器或音色、和弦或和声、人声等内容。通过适当的、已有的算法和模块，可以对这些特征进行单独提取并分析。若加入卷积神经网络，则可获得更为准确的结果。<br>\n参考文献中详细介绍了这二者如何融为一体并实际运用，为接下来的算法思路提供了部分理论基础。</p>\n<h3 id=\"33-现有机器学习算法\"><a class=\"markdownIt-Anchor\" href=\"#33-现有机器学习算法\">#</a> 3.3 现有机器学习算法</h3>\n<p>传统的基于机器学习的音频分类大多基于常规算法，例如支持向量机、决策树、K - 邻近算法、随机森林算法等等。这些算法的优点是部署和训练简单，算法的数学原理完善，但问题是难以准确处理复杂和细微的变化；尤其是在电子音乐风格分类任务中，由于各风格在许多方面非常相似，传统算法无法很好地处理。<br>\n因此，结合使用的技术与特征，提出如下采用神经网络进行识别的识别思路。</p>\n<h3 id=\"331-实践项目deepauddioclassification\"><a class=\"markdownIt-Anchor\" href=\"#331-实践项目deepauddioclassification\">#</a> 3.3.1 实践项目：DeepAuddioClassification</h3>\n<p>在提出自己的算法思路前，笔者首先实践了一个已有的开源项目：<a href=\"https://github.com/despoisj/DeepAudioClassification\">Github: despoisj/DeepAudioClassification</a>；该项目采用 tensorflow 中的 tflearn 模块进行 DNN 训练，并且只对音频频谱进行识别，相当于一个只输入频谱图的图像识别算法。<br>\n通过将音频频谱提取出来并切片，随后基于 DNN 进行图像分类训练，则模型可用于预测一个未知的音乐频谱图。这种方法巧妙地避开了音频数据量过大的问题，因为一般 CD 音质下 44100Hz 意味着 30 秒的音乐就将产生 66 万个长度的向量。但对于原作者的目的而言，分析大类音乐风格的时候可以直接从频谱入手。根据作者发表的文章<a href=\"https://medium.com/@juliendespois/finding-the-genre-of-a-song-with-deep-learning-da8f59a61194#.yhemoyql0\"> Finding the genre of a song with Deep Learning</a> 的描述，只需要每秒 50 像素的分辨率即可获得满意的效果；在这里，sox 提供了很好用的命令行工具，允许我们直接生成灰度频谱图，其中每个像素的 x 代表时间、y 代表频率、亮度代表振幅。切片后使用深度卷积神经网络进行图像训练，最后使用投票机制提高准确率。<br>\n但是，这一次实践的结果并不理想。在学习率 0.001、分辨率 50px/s 时，经过 20 个 epoch 后模型仅能达到 55% 的准确率（ACC），可以看出识别效果并不理想。这主要是因为参与训练的原始数据包括 Trance 和 Hardstyle 两种风格，而它们在梅尔（Mel）频谱图上实际上十分相似，无法准确映射到高维数据集中。</p>\n<h2 id=\"四-srm-dnn频谱-节奏-情感分析-深度神经网络思路\"><a class=\"markdownIt-Anchor\" href=\"#四-srm-dnn频谱-节奏-情感分析-深度神经网络思路\">#</a> 四、SRM-DNN（频谱、节奏、情感分析 - 深度神经网络）思路</h2>\n<h3 id=\"41-电子音乐的频谱特征\"><a class=\"markdownIt-Anchor\" href=\"#41-电子音乐的频谱特征\">#</a> 4.1 电子音乐的频谱特征</h3>\n<p>首先，我们并不希望创建一个需要 A100 才能运行的高度资源密集型网络，而是希望该模型能够在消费级硬件上部署和训练。因此，结合实际电子音乐的主要特征区分，我们可以沿用 DeepAudioClassification 的频谱分析方法。<br>\n对于电子音乐曲风分类而言，其频谱图提供的信息量是非常大的，因为几乎每种主类别都有自己特征的 DnB 序列。这导致了在频谱图中的显著区分，在低频区域尤为明显（见下图）。<br>\n截取频谱图时采用的配置：<br>\n软件：iZotope RX 7<br>\nFFT 类型（type）：自动可变短时傅里叶变换（Auto-adjustable STFT）<br>\n启用重分配（reassignment）：否<br>\n窗函数：海宁窗（Hann）<br>\n颜色映射：青色到橙色（Cyan to orange）<br>\n频率缩放（Frequency scale）：对数（Log）<br>\n高品质渲染（High-quality rendering）：启用<br>\n<img src=\"../_resources/c3f2fb4bdc6d6f2789d569c084686d46.png\" alt=\"c3f2fb4bdc6d6f2789d569c084686d46.png\"><br>\n 图：三种风格的电子音乐频谱图对比<br>\n本图采用的时间窗口：20s</p>\n<p>从对比图中可以很明显地看出，不同风格的电子音乐在频谱图中呈现出较为显著的区别；尽管也有相近的风格（如 Hands Up 和 Hardcore），但总体来说，其频谱图能提供主要的风格信息。<br>\n既然电子音乐的频谱特征如此明显，为什么 DeepAudioClassification 项目却无法使用呢？<br>\n首先，频谱的选型有误，是最大的问题所在。对于电子音乐而言，由于其风格信息大多位于低频区，因此必须使用低频部分缩放较大的谱图类型。上图中采用的缩放是 Log，相比于常用的 Mel 频谱，它对于低频区有更大的缩放等级，使得低频信息分辨率更高；在实际运用中，该软件还提供了 Extend Log（拓展对数）频谱，其低频区的缩放更为显著。<br>\n其次，切片数量过多。实践中为尽量减轻硬件负担，对较长的音频进行切片处理；但每个音频切片数为 100 份，这个设定相对于电子音乐的结构而言太多了。常见的电子音乐由几个类型的分段组成，例如 intro、lead、build up、verse、drop、outro 等；其风格的定义一般主要从 drop 中得出，所以若切片过多，则容易破坏每个分段的完整性，不利于风格识别。</p>\n<h3 id=\"42-鼓与贝斯分析\"><a class=\"markdownIt-Anchor\" href=\"#42-鼓与贝斯分析\">#</a> 4.2 鼓与贝斯分析</h3>\n<p>电子音乐的风格可以说有一半都由 DnB（Drum and bass，鼓与贝斯；这个词同时也是一种类型的电子音乐风格，但本文将其用于指代鼓点 + 贝斯）决定；无论是鼓点节拍数、编排方式还是贝斯的特征，亦或是二者的侧链水平等，均包含大量的风格信息。<br>\n有关如何从音频信号中提取节拍信息，目前已有相关研究成果，包括使用动态编程、神经网络等方法进行识别。参考文献：<a href=\"https://ieeexplore.ieee.org/document/6734668\">Multi-Feature Beat Tracking</a><br>\n 使用 iZotope RX 7 提供的工具也可以进行 DnB 分析，其中的 Music Rebalance 模块可以准确分离人声、贝斯、鼓点三种信号，为分析提供了有利条件。<br>\n<img src=\"../_resources/72bfdc72dfb2f21a37e23d8f647da698.png\" alt=\"72bfdc72dfb2f21a37e23d8f647da698.png\"><br>\n 图：RX 7 中提供的 Music Rebalance 组件</p>\n<h3 id=\"43-bpm与时间分析\"><a class=\"markdownIt-Anchor\" href=\"#43-bpm与时间分析\">#</a> 4.3 BPM 与时间分析</h3>\n<p>BPM，即 Beats per minute，每分钟节拍数。它是音乐的一个重要参数，直接指向音乐的 “速度”。尽管在制作电子音乐时，制作人通常不会严格对齐到小节 / 拍的整数倍，但 BPM 依然能够提供风格信息。<br>\n在主风格分析时，仅通过 BPM 我们即可首先分辨音乐的大致类别；若低于 90 则可能为 Chill Out，90-110 可能为 House，110-130 可能为 Trance、Hands Up，130-160 可能为 Hardstyle 或 Hardcore 等。<br>\n在子风格分析时，BPM 也有助于进行风格确定；例如在 Hardcore 中，若难以分辨 Frenchcore 和 UK Hardcore，则可通过 BPM 辅助判断，若达到了 160 或更高则更可能为 UK Hardcore。<br>\n此外，音频的时间长度同样可以作为网络的输入之一，这是因为 Hands Up、Hardcore、House 和 trance、Chill Out 等分别呈现了两种倾向，前者一般时长为 3 分钟左右，而后者最长可达 10 分钟以上。尽管这种参数的帮助十分有限，但其特征强度还会更高，有助于减少结果的偏离。</p>\n<h3 id=\"44-情感分析\"><a class=\"markdownIt-Anchor\" href=\"#44-情感分析\">#</a> 4.4 情感分析</h3>\n<p>所谓情感分析，指的是对人声（和音乐，如果可能）进行情绪的识别与分类。尽管不是所有音乐都有歌词和人声，电子音乐中的人声更是少见，但进行情感分析依然有助于进一步判别细微的风格差异。<br>\n不过，这一步的主要目的其实只针对一种风格的音乐，即 trance；许多 Trance 都具有一些人声，即便没有人声，对于音乐本身的情感分析也能够帮助辨别 Progressive trance 和 Uplifting trance。这是因为大部分 Uplifting trance 都具有一些独特的情感特征：Hopeful，Sentimental，Sad 等等；它们具有一个共同的特征，就是 uplifting，即鼓舞人心的。可以说，如果一首 Trance 听着让人想流泪，则多数时候可以确定它一定是 Uplifting trance。<br>\n参考文献：<a href=\"https://www.hindawi.com/journals/misy/2022/2715765/\">Music Emotion Classification Method Using Improved Deep Belief Network</a></p>\n<h3 id=\"45-能量分析\"><a class=\"markdownIt-Anchor\" href=\"#45-能量分析\">#</a> 4.5 能量分析</h3>\n<p>所谓能量分析，是指针对音频每个分片（如每秒）进行电平、响度、频域复杂度等进行分析，从而确定该分片的能量等级。由于电子音乐中每个分段的能量差异较大，intro/outro 最低、lead/build up 中等、drop 最高，因此对整个音频进行能量分析并在二维数组中呈现，将有助于分析音乐结构。<br>\n例如，trance 音乐的结构中，各分段能量差异相对较小，drop 出现的频次更多；House 则一般为 intro、lead、build up、drop、verse、build up、verse、outro 序列。不过该方法适用性不佳，主要是因为电子音乐的结构变化性大，且目前没有已标签的数据集进行训练，需要人工标记才能进行监督学习。</p>\n<h3 id=\"46-实现思路\"><a class=\"markdownIt-Anchor\" href=\"#46-实现思路\">#</a> 4.6 实现思路</h3>\n<p>有了以上理论基础，我们就可以尝试构建这样一个神经网络了。当然，由于笔者的专业是食品安全，本文并不涉及任何实际代码、构建和部署，而仅为提出思路。</p>\n<h4 id=\"461-频谱提取\"><a class=\"markdownIt-Anchor\" href=\"#461-频谱提取\">#</a> 4.6.1 频谱提取</h4>\n<p>这个网络仅涉及频域分析而没有时域处理，因此我们可以直接忽略音频原始采样，而是直接生成其频谱图。<br>\n前文实践项目 DeepAudioClassification 中，使用到了一个命令行工具：sox。它可以输出音频的 png 频谱图，并且可以直接定义灰度、分辨率等；但其选项中并不能更改频率缩放类型，而默认情况下的 Mel 频谱图对于电子音乐分类而言效果不佳。因此，我们应该使用其他工具或算法来创建 log 频谱图。在 log 频谱图下，一个 44100Hz 采样率的音频（其最高频率为 22050Hz），频谱图的中间位置约为 2205Hz。</p>\n<h4 id=\"462-dnb分析\"><a class=\"markdownIt-Anchor\" href=\"#462-dnb分析\">#</a> 4.6.2 DnB 分析</h4>\n<p>网络的第二个输入应该为 DnB 序列；通过前文所述的一些方法，可以获取音乐的节拍序列信息。仅需得知 drum（鼓点）的序列即可提供良好的分类所需的信息，而 bassline 则可通过分析甚低频区的信号得出。<br>\n这两个数据在训练时应始终保持时间一致性，即 drum 和 bass 不能独立分析；也可考虑混合后输入，或直接从频谱图中再单独提取高分辨率的低频区信号频谱图像进行输入。<br>\n可能实现的模块：<a href=\"https://github.com/MTG/essentia/\">Github: MTG/essentia</a></p>\n<h4 id=\"463-bpm与时间分析\"><a class=\"markdownIt-Anchor\" href=\"#463-bpm与时间分析\">#</a> 4.6.3 BPM 与时间分析</h4>\n<p>这一步是相对而言最简单的，音频时间直接获取 duration 即可，BPM 也可以通过许多 python 的音频工具库获得。<br>\n可能实现的模块：<a href=\"https://github.com/librosa/librosa\">Github: librosa/Librosa</a></p>\n<h4 id=\"464-图像识别\"><a class=\"markdownIt-Anchor\" href=\"#464-图像识别\">#</a> 4.6.4 图像识别</h4>\n<p>这一步有许多可选的方向，不过仍然可以参考前文实践项目的做法，使用 tensorflow 提供的 tflearn 进行图像训练。需要注意的是，为了降低负载，仍然可能需要对频谱图进行分片处理。</p>\n<h4 id=\"465-人声分离\"><a class=\"markdownIt-Anchor\" href=\"#465-人声分离\">#</a> 4.6.5 人声分离</h4>\n<p>借助许多工具，包括 iZotope RX 7 的 Center Extract、Music Rebalance 或 Audition 的中置声道提取功能，都可以对音频的人声进行高质量分离。这一步的目的是为后续进行情感分析提供原始文件，并且也可能为音乐情感分析提供良好的无人声音轨。</p>\n<h4 id=\"466-情感分析\"><a class=\"markdownIt-Anchor\" href=\"#466-情感分析\">#</a> 4.6.6 情感分析</h4>\n<p>参考文献：<a href=\"https://www.hindawi.com/journals/misy/2022/2715765/\">Music Emotion Classification Method Using Improved Deep Belief Network</a><br>\n 基于此文献，可以确定 DBN 网络用于情感分析的可能性。不过目前似乎很少见到相关的模块或库可以直接提供此功能接口的，因此在编程方面可能具有难度。</p>\n<h2 id=\"5总结\"><a class=\"markdownIt-Anchor\" href=\"#5总结\">#</a> 5. 总结</h2>\n<p>再次说明，由于作者为食品专业，且对机器学习、计算机等了解很少，本文中可能出现大量不专业、错误术语和概念，其中的部分思路也可能无法实现或已有更好的替代方法。但作者编写本文的原因是希望解决实际问题，现有的音乐分类不够准确和细致、无法区分电子音乐下的各类风格。<br>\n如果您有建议、修改提示、想法等，均可直接于评论区留言。人工智能是新兴的热门话题，在时代的风口浪尖上，我们可以共同学习、不断进步，为计算机学习的城墙添砖加瓦。</p>\n",
            "tags": [
                "信号处理",
                "深度学习",
                "音频"
            ]
        },
        {
            "id": "https://zjxdiu.github.io/zwork.io/blog/FTIR%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/",
            "url": "https://zjxdiu.github.io/zwork.io/blog/FTIR%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/",
            "title": "傅里叶变换红外光谱技术原理详解",
            "date_published": "2022-11-26T13:02:00.000Z",
            "content_html": "<h2 id=\"目录\"><a class=\"markdownIt-Anchor\" href=\"#目录\">#</a> 目录</h2>\n<p>一、物理基础<br>\n 1.1 红外光谱基本原理<br>\n 1.2 FTIR 光谱仪构成与基本运行过程<br>\n 1.3 干涉现象<br>\n 1.3.1 波的叠加<br>\n二、信号与系统<br>\n 2.1 数字、模拟信号<br>\n 2.1.1 信号<br>\n 2.1.2 模拟信号<br>\n 2.1.3 数字信号<br>\n 2.2 信号转换<br>\n 2.2.1 采样与 A/D 转换<br>\n 2.2.2 奈奎斯特采样定理<br>\n 2.2.3 混叠<br>\n 2.3 傅里叶变换（FT）<br>\n三、FT 在 FTIR 中的具体原理<br>\n 3.1 仪器工作流程详解<br>\n 3.2 信号检测与采样<br>\n 3.3 数据处理<br>\n四、总结与展望<br>\n 4.1 总结与心得<br>\n 4.2 未来展望</p>\n<h1 id=\"傅里叶变换红外光谱技术原理详解\"><a class=\"markdownIt-Anchor\" href=\"#傅里叶变换红外光谱技术原理详解\">#</a> 傅里叶变换红外光谱技术原理详解</h1>\n<h2 id=\"一-物理基础\"><a class=\"markdownIt-Anchor\" href=\"#一-物理基础\">#</a> 一、物理基础</h2>\n<h3 id=\"11-红外光谱基本原理\"><a class=\"markdownIt-Anchor\" href=\"#11-红外光谱基本原理\">#</a> 1.1 红外光谱基本原理</h3>\n<p>当一束红外光射到物质上，可能发生：吸收、透过、反射、散射或者激发荧光。其中，我们需要的部分是吸收的量。然而，对于仪器来说，直接测量吸光度似乎并不现实；因此，我们一般采用已知强度的光源以及透过量来代替吸光度。<br>\n红外光，本质上是一段频率特殊、无法被人眼看见的电磁波，其波长一般为 0.75-1000nm，频率约为 300GHz~430THz。与之相似的包括微波（或 Wi-Fi、5G 网络的毫米波）、FM 广播等无线电波和其它。<br>\n对于红外光谱分析，我们一般选用其中的一段波长（或频率、波数）为目标光。采用色散元件，我们可以将光源发射的连续光谱（类似包含全部可见光波长而显白色的太阳光）分解为需要的单色光（只包含一种波长的光），然后让其通过样品、测定吸光度。<br>\n其余的红外光谱原理可查阅课本，此处不再赘述。</p>\n<h3 id=\"12-ftir光谱仪构成与基本运行过程\"><a class=\"markdownIt-Anchor\" href=\"#12-ftir光谱仪构成与基本运行过程\">#</a> 1.2 FTIR 光谱仪构成与基本运行过程</h3>\n<p>FTIR 光谱仪，即 Fourier Transform Infrared Radiation Spectrometer，傅里叶变换红外辐射光谱仪（以下简称 FTIR 或 FFTIR），就是一种用于红外光谱测定的仪器。与普通的红外光谱仪不同，FTIR 不具有单色器，而是以迈克尔逊干涉仪取代，并且对计算机系统尤为依赖、几乎不可能通过人力来计算其光谱图。<br>\nFTIR 的运行流程可以概括为：光源发射红外线 – 干涉仪动作产生干涉光 – 干涉光通过样品到达检测器 – 光电二极管或其它检测器将光强转换为电信号 – 传入计算机进行数据处理。其中，光源发射的红外线包括整个需要测定的频率范围，而干涉仪需要持续动作以产生需要的干涉光；干涉光的性质与检测器信号是一一对应且已知的。</p>\n<h3 id=\"13-干涉现象\"><a class=\"markdownIt-Anchor\" href=\"#13-干涉现象\">#</a> 1.3 干涉现象</h3>\n<p>1801 年，英国物理学家托马斯・杨在实验室里成功地观察到了光的干涉，以下就是经典的双缝干涉实验。<br>\n<img src=\"../_resources/d6cfc0c663cbda269660f8f4e96683a7.png\" alt=\"双缝干涉现象.png\"></p>\n<p>简而言之，同一束光线从不同的位置发出时，在后面的空间内就会发生干涉现象；或者说，当一束光 “碰到” 另一束光时，两束光发生干涉现象。通俗的例子是，当身边有一个持续频率的声音（例如蜂鸣器报警），人站在房间的不同位置就会听到音量大小不同，在某些角落时这个声音甚至会几乎完全消失，这也是干涉现象的一种体现。</p>\n<h4 id=\"131-波的叠加\"><a class=\"markdownIt-Anchor\" href=\"#131-波的叠加\">#</a> 1.3.1 波的叠加</h4>\n<p>我们都知道如何画 y=sin x 的函数图像，它是一个正弦曲线。但是，如果在同一个空间和时间内，有另一个波源发射了另一个正弦曲线，并且它的解析式是 y=sin (1.1x)，这时候两个波发生叠加，我们又如何画出 y= (sin x) + sin (1.1x) 的曲线图呢？<br>\n<img src=\"../_resources/d02ac3e559fc44f7eb9ca6216a6c5b97.png\" alt=\"波的叠加图.png\"></p>\n<p>使用现代化的图形计算器，我们可以很轻松地通过计算机画出上述叠加波的函数图像。很明显，叠加波的振幅（也就是一个周期内的最大 y 值）在周期性变化，但我们仍然可以看到 sin x 的痕迹；似乎就是 sin x 的振幅被周期性地 “压缩”，而这个压缩的方式仍然是一个正弦样子。<br>\n也许这些内容已经难以理解了，但我们只需要知道，多个波在叠加之后会产生新的波，而这个叠加波的形态与每个单独的波似乎没有太过直接的关联。</p>\n<h2 id=\"二-信号与系统\"><a class=\"markdownIt-Anchor\" href=\"#二-信号与系统\">#</a> 二、信号与系统</h2>\n<h3 id=\"21-数字-模拟信号\"><a class=\"markdownIt-Anchor\" href=\"#21-数字-模拟信号\">#</a> 2.1 数字、模拟信号</h3>\n<h4 id=\"211-信号\"><a class=\"markdownIt-Anchor\" href=\"#211-信号\">#</a> 2.1.1 信号</h4>\n<p>所谓信号，指的是能传递信息的某种载体。例如现在屏幕上显示的文字，就是一种传递文字信息的信号。这是一个抽象的概念，但有太多实际的例子。接下来的篇幅里，我们将大量使用声音，一种最常见的信号为例，讲解信号与系统的浅层内容。</p>\n<h4 id=\"212-模拟信号\"><a class=\"markdownIt-Anchor\" href=\"#212-模拟信号\">#</a> 2.1.2 模拟信号</h4>\n<p>所谓模拟信号，指的其实是连续的信号；例如我们听到的声音，实际上是声源产生的机械振动，导致空气被压缩和扩张，这个不断变化的气压传入耳朵，再通过复杂的器官系统，我们就能听到声音。这个过程中，物体的机械振动是连续的，它并不会突变。如果难以理解，那么可以想象一下，如果一个物体的振动发生了一次突变，这意味着它振动面上的分子发生了瞬间移动，也就是在 0 秒内产生了大于 0 的位移，其速度超过了光速；显然，这对于声波来说是不可能的。因此，我们听到的声音就是连续的信号。</p>\n<h4 id=\"213-数字信号\"><a class=\"markdownIt-Anchor\" href=\"#213-数字信号\">#</a> 2.1.3 数字信号</h4>\n<p>数字信号，也可以叫离散信号，是信号的一种类型。这个名词听上去很高级，但实际上它跟模拟信号没有太大的区别。它们都是信号，只不过形式不同。<br>\n我们知道，模拟信号是连续的信号。仍然以声波为例，如果我们将声音与时间的关系画在一张图上，这就是所谓的声波图。<br>\n<img src=\"../_resources/3ac9e78249d54b91cda7d894e5a661c3.png\" alt=\"声波图1.png\"></p>\n<p>现在，假设我们希望保存下来这一段声波，并希望它能在一定条件下重现出来。但是，模拟信号是连续的，这意味着它在时间上不存在断点，它包含的数值为无穷多个。显然，计算机无法记录无穷多个数据，实际上我们也没有必要全部记录下来。我们只需要每隔一段时间记录一个数据，这样就可以将无限的数据变成有限，并且似乎也有很大的希望能够重现出来（至少在能接受的损失范围内）。这个过程与逻辑将在下文介绍。</p>\n<h3 id=\"22-信号转换\"><a class=\"markdownIt-Anchor\" href=\"#22-信号转换\">#</a> 2.2 信号转换</h3>\n<h4 id=\"221-采样与ad转换\"><a class=\"markdownIt-Anchor\" href=\"#221-采样与ad转换\">#</a> 2.2.1 采样与 A/D 转换</h4>\n<p>刚才我们提到了模拟信号转换到数字信号的过程。实际上，这就是 ADC（Analog to Digital Converter，模拟到数字转换）的工作原理。我们只需要在尽可能短的时间间隔内记录数据，这样至少主观上我们就可以重现它。<br>\n<img src=\"../_resources/4561bc52e3a14c62efb44bf598c3ee35.png\" alt=\"采样过程.png\"></p>\n<p>这张图展示的就是一个正弦波经过转换后的结果，每个圆圈代表一个数据点；这样，无限的信号变成了有限的数据点，我们也能通过点的走向看出来它是一个正弦波。这个过程，我们称之为 “采样”（Sampling）。采样的结果，就是将连续信号转换为有限个的采样点（Sample）。<br>\n反之，我们也可以通过 DAC 过程，将采样后的离散信号再次转换回模拟信号；这样，你存储在手机里的音乐就能再次变成连续的电信号，并通过扬声器的振膜再变成机械振动。由于这个过程涉及过多的电子工程学内容，并且对于本文所论述的信号处理而言没有太大价值，因此不在此处展开。</p>\n<h4 id=\"222-奈奎斯特采样定理\"><a class=\"markdownIt-Anchor\" href=\"#222-奈奎斯特采样定理\">#</a> 2.2.2 奈奎斯特采样定理</h4>\n<p>现在，我们知道了采样的过程，就是用大量的数据点来描述原信号。但是，这个大量到底是多少？我们说 “尽可能短的时间间隔内”，这个间隔到底是多少？<br>\n在回答以上问题之前，我们先想象一下刚才的采样图：里面有很多的数据点，因此我们可以 “脑补” 出原来的信号。但是如果数据点太少，我们还能这样 “脑补” 吗？显然，可能就会有损失，甚至会丢失。<br>\n庆幸的是，我们有一个定理，它给出了这个最小数据点数的限制，它就叫奈奎斯特采样定理。<br>\n奈奎斯特定理的原文是：任何有限带宽的连续信号都可以被完美转换为数字信号，只要采样频率高于原信号中最高频率分量的 2 倍。<br>\n太长了看不懂，没关系，我们分别来解释一下它的含义。</p>\n<p>首先，我们要知道采样率的定义。刚才说到的 “最小时间间隔”，其实就是指采样点的间隔；而它的倒数就是采样率。采样率的含义是，每秒的采样点数量，单位是 Hz（赫兹）。<br>\n然后，我们有一个信号频率的概念；我们知道，人耳能听到的声音频率范围是 20-20kHz，这里的频率指的是声源机械振动的频率。<br>\n现在，我们希望录音机能够回放的声音频率覆盖人耳的听觉频率范围，这样它录制的声音才跟最开始的声音能尽可能地一致。现在就轮到奈奎斯特定理上场了，我们的录音机采样率需要＞20kHz x 2 = 40kHz，才能保证它可以记录到人耳的听觉上限。<br>\n没错，奈奎斯特定理就是这么简单的应用。如果我们想将一个最高频率为 100Hz 的信号无损转换为数字信号，我们的采样率就要大于 200Hz，仅此而已。实际上，多数现代音频以 44.1kHz 或 48kHz 的采样频率进行采样，以保证完全覆盖人耳听觉频率范围。<br>\n这就结束了吗？奈奎斯特定理真的能如此简单和完美地指导我们开发电子设备吗？显然不是的。它只是一种理想情况下的描述，实际上我们的仪器采样率都是有限的，存储设备的空间也是有限的，这就意味着很多时候我们的采样率并不能达到要求的 2 倍于最高频率（我们称之为奈奎斯特频率，以下简称 Nf），而这时候，我们就遇到了采样过程的最大问题 —— 混叠。</p>\n<p>这里还有一个小插曲，你可能会说，采样之后的数字信号是离散的数据点，它怎么能够无损转换回模拟信号呢？我难道不可以在数据点之间随便画我想要的图形吗？<br>\n很抱歉，你确实不可以。这就是奈奎斯特采样定理的美丽之处了，它从数学上证明了，我们还原回去的那个信号，就是这一段数字信号转换到模拟信号时的唯一解。如果你试图在其中画更多的内容，那么它就会产生高于奈奎斯特频率的内容，那么在还原时由于频率的限制，这些内容就会丢失，最后仍然会变成原来的波形。</p>\n<h4 id=\"223-混叠\"><a class=\"markdownIt-Anchor\" href=\"#223-混叠\">#</a> 2.2.3 混叠</h4>\n<p>什么是混叠（Aliasing）？<br>\n我们从一个生活中常见的例子来说明 —— 车轮效应。<br>\n如果你在电视上看节目，或者自己拍摄视频，然后画面里包含了汽车、自行车的车轮运动，你可能会注意到一个奇怪的现象：当车从停止开始加速时，你看到画面里的车轮逐渐加快；但当加速到一定水平后，不仅车轮没有更快，反而逐渐开始减速，直到某个时候车轮在画面里看起来跟静止一样；如果车继续加速，你甚至会看到车轮开始反方向旋转。<br>\n没错，这就是混叠；确切来说，是图像信息在时间域上的混叠。<br>\n发生车轮效应的原因是，摄像机的拍摄并不是记录连续的运动画面，而是相当于一个快速连拍的过程，它每秒拍摄一定数量（一般是 24 或 30）的照片，然后在你观看视频的时候以相同的速度快速播放照片；由于人眼的视觉暂留，我们就看到的连续的运动画面。<br>\n但是，你可能已经注意到了，这里摄像机并没有记录原始的连续画面，它的工作更像是一个 “采样” 的过程。是的，这确实是一种采样，并且我们看到了采样过程中最大的问题：混叠。它发生在采样速率小于 Nf 的时候，并且会导致一些严重的后果（例如车轮反转）。<br>\n理解起来也很容易。假设我们的手机每秒拍 30 张照片（在视频里称为 “帧”），这意味着相邻两帧的间隔是 1/30s=33.3ms。如果车轮的运动速度够快，那么就可能发生一个情况：在这 33.3ms 的时间间隔之内，车轮刚好转过了一圈（或 1/n 圈，取决于车轮形状），这意味着第二帧和第一帧的画面是完全一样的。以此类推，如果车速维持在这个水平，那么我们将看到车轮一直静止。<br>\n在信号领域，混叠的含义几乎是一样的，当我们的信号包含了大于采样率的频率，此时就会发生混叠现象，这会向已经采样的数据添加伪影，并且一旦它进入了数字信号，就无法消除。<br>\n* 更多信息和通俗的动画解释：<a href=\"https://www.bilibili.com/video/BV14q4y1Z7bx\">点击查看 b 站视频</a></p>\n<h3 id=\"23-傅里叶变换ft\"><a class=\"markdownIt-Anchor\" href=\"#23-傅里叶变换ft\">#</a> 2.3 傅里叶变换（FT）</h3>\n<p>* 本节部分内容源自<a href=\"https://www.cnblogs.com/h2zZhou/p/8405717.html\">原文地址</a>，作者：韩昊</p>\n<p>现在，我们已经获得了一些采样好的数字信号，假设这些信号非常完美，不会发生混叠。我们随时可以用 DAC 过程将其转换回模拟信号，也可以存储在硬盘里以便之后使用。那么，我们还要傅里叶变换干什么？傅里叶变换到底是个什么东西？<br>\n我们用一个最直观的方式理解傅里叶变换。<br>\n在你的理解中，一段音乐是什么呢？<br>\n<img src=\"../_resources/d91b563e232fd309b8767eb75ffdb1a3.png\" alt=\"声波图2.png\"><br>\n 这是我们对音乐最普遍的理解，一个随时间变化的振动。<br>\n但是，对于精通乐器的人来说，音乐更直观的理解也许是这样的：<br>\n<img src=\"../_resources/f5352b530b102b22e4fc160fc4bac229.png\" alt=\"五线谱图.png\"></p>\n<p>好了，傅里叶变换到此结束，我们继续下一章的学习。<br>\n什么？这还不够吗？<br>\n其实这是一个不太恰当的例子，但它通俗地解释了 FT（傅里叶变换）的过程：将一段随时间变化的声波（时域信息）转换为随时间变化的音调（频域信息）。FT 过程在无限的时间上识别信号，然后把其中的频率信息提取出来，并转换成有限的频率谱图。<br>\n不过，我们到底怎么实现 FT 呢，一段声波信号看起来那么复杂、毫无规律，我们怎么提取其中的频率信息？<br>\n傅里叶变换认为，所有的叠加波，都可以由有限或无限个已知或已知规律的正弦波叠加而成。而处理正弦波是非常轻松的，只需要找到它的周期，就能知道它的频率，还能得知它的表达式，甚至将其替换为另一个不同频率的正弦波。<br>\n如果还不够直观，我们看一下两段音乐的声波图：<br>\n<img src=\"../_resources/71d799eeb29fc6ba5fbc0693c28c96aa.png\" alt=\"声波图3.png\"></p>\n<p><img src=\"../_resources/be31756d0721cf2caaafc700b22aa00e.png\" alt=\"声波图4.png\"><br>\n 上图是电子音乐，包含强烈鼓点、贝斯（低频）声音，而下图则是钢琴曲，这些低频声音很少。<br>\n也许你已经看出来其中的区别了，低频声音占比高的声波，它的图像会呈现一个十分 “低频” 的起伏；而在同样的窗口内，低频占比小的声波则显得 “复杂” 很多，并且缺乏更大的起伏波浪。仔细观察上图，其实在起伏的过程中也包含很多小的尖刺，实际上这就是低频声音与高频声音叠加之后的结果。<br>\n现在，你已经掌握了用肉眼做傅里叶变换的能力（），但是这个计算精度很差，也只能区分少数的几个频率（这就是为什么人来算傅里叶变换几乎不可能的原因）。不过，计算机很擅长这个，让它来做 FT（确切来说是 FFT，快速傅里叶变换，是针对计算机的一种优化算法），我们就能得到音乐的频谱图（颜色越亮表示声音强度越高）：<br>\n<img src=\"../_resources/f55b89e1692387413e2ee5f233dc93bb.png\" alt=\"频谱图.png\"></p>\n<p>（准确地说，这张图是频谱随时间变化的图，因为音乐信号中的频率信息时刻变化）<br>\n这个图对于音频工程师来说简直就是一个神器；把声波转换为频率信息，我们可以发现很多原来不能发现的错误和问题；如果一些乐器声音太大导致刺耳的话，频谱图上就能看到高频部分的强度很高。<br>\n在其它需要分析信号的领域，FT 同样是好用的工具。它把复杂的信号做了简化，让我们能从另一个维度（视角）来观察信号。<br>\n* 如果还感有余力，则可以详细了解拉普拉斯变换，它又从另一个维度理解了信号。</p>\n<h2 id=\"三-ft在ftir中的具体原理\"><a class=\"markdownIt-Anchor\" href=\"#三-ft在ftir中的具体原理\">#</a> 三、FT 在 FTIR 中的具体原理</h2>\n<h3 id=\"31-仪器工作流程详解\"><a class=\"markdownIt-Anchor\" href=\"#31-仪器工作流程详解\">#</a> 3.1 仪器工作流程详解</h3>\n<p>对于 FTIR 而言，我们有红外光源、干涉仪（包含两个反射镜，一个是动镜，一个是定镜），He-Ne 激光器，样品池，检测器，计算机系统。红外光源会持续发射连续的红外光谱，而动镜则利用激光校准、通过电机来调整位置，使之能够在确定的距离上进行移动；入射红外光在透镜作用下分成两束光，并在经过动镜和定镜后再次合为一束，在这个过程中两束光交汇即产生干涉现象，而其相位差就由动镜位置决定。动镜不断移动，干涉相位也在不断变化，这一束干涉光送入样品池后被吸收一部分，最后进入检测器和信号系统中。<br>\n<img src=\"../_resources/d156e5d7fb71c932d8ebc2153d08941e.png\" alt=\"光线走向FTIR.png\"></p>\n<p>这张图很好地解释了 FTIR 中各光线的走向。其中，Beamsplitter 是光波分束器，也叫半透半反射镜，它的作用是将红外光源发射的光线分为两束，一束为绿色实线，另一束为红色实线；它们分别到达定镜和动镜，并被反射回来（反射光用绿色、红色虚线表示）。反射光到达分束器时也会发生同样的现象，我们需要的光线是绿色穿透线和红色反射线（虚线），它们在分束器处就会发生干涉现象，最后干涉光到达样品。</p>\n<h3 id=\"32-信号检测与采样\"><a class=\"markdownIt-Anchor\" href=\"#32-信号检测与采样\">#</a> 3.2 信号检测与采样</h3>\n<p>通过前文信号与系统部分的学习，我们知道，仪器是不能处理连续信号的，必须通过采样、转换为数字信号才可以进行处理和储存。不过，与音频（和大多数）信号不同的是，FTIR 中信号并不是随时间变化，而是随动镜位置变化的。当动镜固定在一个位置时，得到的信号永远是同一个值。这就给了我们的仪器一些 “可乘之机”。<br>\n如果了解过示波器或相关产品，那么你一定会知道，现在的实验室示波器带宽一般不会超过 10GHz（最大带宽，指在这个频率以内的信号都能被较为准确地还原和记录），而红外光的频率在 300GHz 到 430THz 之间，它们之间的差距非常大；尽管这个对比并不恰当，但我们依然能发现，通过时间来采样显然是不合适的。<br>\n理解了这些，我们就能知道 FTIR 到底是如何采集数据的了；动镜每次移动很短的距离，然后两束光的相位会发生变化（光程差改变），进而引起干涉发生在不同的光频率上。这个动镜单次移动的距离非常短，以至于要单独用 He-Ne 激光来进行位置调整。具体是如何做到的，我并没有找到对应的资料，如果有同学知道可以在评论区告知。</p>\n<h3 id=\"33-数据处理\"><a class=\"markdownIt-Anchor\" href=\"#33-数据处理\">#</a> 3.3 数据处理</h3>\n<p>现在，动镜完整地移动了一个循环，其中每次停顿的时候检测器都记录了一个数值，这个数值代表动镜在这个位置的时候这种干涉光导致的透过程度。将这些数值与动镜位置的关系作图，即得干涉图。对干涉图作 FFT 运算，即得每个频率（波数）下的吸光度（透过率）。<br>\n如果难以理解，这里有一个解释的过程。<br>\n假设我们的红外光源只会发射两个频率的波（即两个单色光），它们的频率有一定的差异。现在，这两束光经过了一次完整的工作循环，则在干涉仪中，两束光会发生干涉现象，且这个干涉会随动镜位置的改变而变化。我们将动镜的位置类比到音频信号中的时间，将检测器的结果理解为量化后的强度值，则得到的干涉图实际上是一种强度 - 时间的时域图；FFT 可以将其转变为光谱图，实际上是一种强度 - 频率（波数）的频域图。只不过在音频信号中，频率指的是振动次数 / 秒，而光谱中频率指的是波数 / 厘米。<br>\n<img src=\"../_resources/bb116765d12239882d80f86789823e40.png\" alt=\"干涉与谱图.png\"></p>\n<p>左图为干涉图，右图为光谱图。可以将干涉图类比为时域信号图（如声波图），将光谱图类比为频域信号图（频谱图）。</p>\n<h2 id=\"四-总结与展望\"><a class=\"markdownIt-Anchor\" href=\"#四-总结与展望\">#</a> 四、总结与展望</h2>\n<h3 id=\"41-总结与心得\"><a class=\"markdownIt-Anchor\" href=\"#41-总结与心得\">#</a> 4.1 总结与心得</h3>\n<p>FTIR 是目前应用最多的红外光谱分析原理，因为它与标准的红外光谱分析法相比，具有检测速度快、灵敏度更高、信噪比更高等优势。但目前大学相关仪器分析教材中并未详细描述 FTIR 的原理，甚至网络上都很难直接搜索到 FTIR 的详细原理（大部分都是以某乎的回答形式，而那些回答要么直接抄教材、FFT 部分一笔带过，要么过于复杂、直接摆上一长串的变换公式，这对于想稍微深入理解但又没有学习过信号与系统的化学相关专业学生来说实在不友好）。因此，我在查找了大量的资料的情况下才有了撰写这篇文章的想法。<br>\n我并不是多学位、辅修第二专业的学生，但我对音频处理、电子工程都有所了解和学习。这一次在食品专业课程中看到了相关的技术，我几乎是瞬间就产生了浓厚的兴趣。尽管学习的过程十分艰难，这篇文章最终还是诞生了，以期有相同兴趣的同学可以得到帮助。</p>\n<h3 id=\"42-未来展望\"><a class=\"markdownIt-Anchor\" href=\"#42-未来展望\">#</a> 4.2 未来展望</h3>\n<p>由于大三时期学习事务繁多，本文从 2022 年 11 月 22 日开始编写，到 26 日了才勉强算接近尾声。因此，文章内仍然有很多错误没能及时发现与更正，若能指正，感激不尽。<br>\n实际上我还学习了更多的内容，例如旁瓣峰与窗函数、信号补零的影响等等，但最终都并未写入本文。若有兴趣了解，可联系我提供相关学习资料地址等。</p>\n",
            "tags": [
                "化学",
                "仪器分析",
                "信号处理"
            ]
        }
    ]
}